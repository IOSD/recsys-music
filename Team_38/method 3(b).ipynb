{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I have used the movies dataset(100K) since the song dataset(1000K) which I used in method 1,method 2 was quite large\n",
    "This method uses the keras library without neural network\n",
    "We will try to make features of user and item using known rating\n",
    "We will then use these learnt features to predict new rating\n",
    "'''\n",
    "#Importing necessary liraries\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.constraints import non_neg\n",
    "import numpy as np\n",
    "import keras.models as kmodels\n",
    "import keras.layers as klayers\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Size of our full dataset###\n",
      "\n",
      "(100000, 4)\n"
     ]
    }
   ],
   "source": [
    "#Collecting the necessary movielens data\n",
    "data=pd.read_csv(r\"C:\\Users\\shashank\\Desktop\\music recommendation\\ml-100k\\u.data\" \\\n",
    ",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))\n",
    "\n",
    "'''\n",
    "data.user_id = data.user_id.astype('category').cat.codes.values\n",
    "data.item_id = data.item_id.astype('category').cat.codes.values\n",
    "'''\n",
    "print('###Size of our full dataset###')\n",
    "print()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###Size of our training dataset\n",
      "(80000, 4)\n",
      "\n",
      "###Size of our test dataset\n",
      "(20000, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all_user contains id of all users\n",
    "all_user = data['user_id'].unique().tolist()\n",
    "#all_item contains id of all items\n",
    "all_item = data['item_id'].unique().tolist()\n",
    "\n",
    "#dict1(dictionary) contains modified ids of users between 0 and len(all_user)\n",
    "dict1 = {j:i for i,j in enumerate(all_user)} \n",
    "#dict2(dictionary) contains modified ids of users between 0 and len(all_item)\n",
    "dict2 = {j:i for i,j in enumerate(all_item)} \n",
    "\n",
    "#below for loop will convert old ids to new ids present in dict1 and dict2\n",
    "for item,row in data.iterrows():\n",
    "\trow['user_id'] = dict1[row['user_id']]\n",
    "\trow['item_id'] = dict2[row['item_id']]\n",
    "\n",
    "#Splitting of data\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "print()\n",
    "print('###Size of our training dataset')\n",
    "print(train.shape)\n",
    "print()\n",
    "print('###Size of our test dataset')\n",
    "print(test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#users contain all unique user id\n",
    "users = len(data.user_id.unique())\n",
    "#movies contain all unique movie id\n",
    "movies = len(data.item_id.unique()) \n",
    "print('')\n",
    "#total features we would like to learn for user and movie\n",
    "features = 30\n",
    "\n",
    "movie = keras.layers.Input(shape=[1],name='movie_input')\n",
    "#this creates a feature space for item\n",
    "feature_space_movie = keras.layers.Embedding(movies , features, name='movie_feature_space',embeddings_constraint=non_neg())(movie)\n",
    "movie_flattened = keras.layers.Flatten()(feature_space_movie)\n",
    "\n",
    "user = keras.layers.Input(shape=[1],name='user_input')\n",
    "#this creates feature space for user\n",
    "feature_space_user = keras.layers.Embedding(users, features,name='User_Feature_space',embeddings_constraint=non_neg())(user)\n",
    "user_flattened = keras.layers.Flatten()(feature_space_user)\n",
    "#using dot product to make desired rating\n",
    "model = keras.layers.dot([movie_flattened, user_flattened],axes=1)\n",
    "\n",
    "result = keras.Model(inputs=[user, movie],outputs=[model])\n",
    "\n",
    "result.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_feature_space (Embedding) (None, 1, 30)        50460       movie_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "User_Feature_space (Embedding)  (None, 1, 30)        28290       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 30)           0           movie_feature_space[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 30)           0           User_Feature_space[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 78,750\n",
      "Trainable params: 78,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 13s 168us/step - loss: 5.2474\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 13s 167us/step - loss: 1.1022\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 13s 167us/step - loss: 0.9473\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 13s 166us/step - loss: 0.9207\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 13s 167us/step - loss: 0.9086\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 14s 169us/step - loss: 0.9037\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 14s 174us/step - loss: 0.9010\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 14s 178us/step - loss: 0.8969\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 14s 179us/step - loss: 0.8904\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 14s 178us/step - loss: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2078002e048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will make 10 iterations through full train dataset\n",
    "result.fit([train.user_id, train.item_id], train.rating, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###The mean square error on Training set is: 0.7212870818689465\n",
      "\n",
      "###The mean square error on Test set is: 0.7559667684065178\n"
     ]
    }
   ],
   "source": [
    "predicted = result.predict([train.user_id, train.item_id])\n",
    "actual = train.rating\n",
    "print()\n",
    "print('###The mean square error on Training set is: '+str(mean_absolute_error(predicted, actual)))\n",
    "predicted = result.predict([test.user_id, test.item_id])\n",
    "actual = test.rating\n",
    "print()\n",
    "print('###The mean square error on Test set is: '+str(mean_absolute_error(predicted, actual)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
